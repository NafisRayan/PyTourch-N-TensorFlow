<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Transparent THREE.js with TensorFlow Object Detection Background</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
</head>
<body class="m-0 p-0 overflow-hidden">
    <canvas id="detection-canvas" class="fixed top-0 left-0 w-full h-full object-cover"></canvas>
    <div id="threejs-container" class="fixed top-0 left-0 w-full h-full"></div>

    <script type="module">
        window.onload = () => {
            // Load the COCO-SSD model
            let model;
            cocoSsd.load().then(loadedModel => {
                model = loadedModel;
                console.log("Model loaded.");
                detectObjects();
            });

            // Handle window resizing
            window.addEventListener('resize', () => {
                camera.aspect = window.innerWidth / window.innerHeight;
                camera.updateProjectionMatrix();
                renderer.setSize(window.innerWidth, window.innerHeight);
            });

            // TensorFlow.js object detection setup
            const canvas = document.getElementById('detection-canvas');
            const ctx = canvas.getContext('2d');

            // Scaling factor for video feed
            const scaleFactor = 1.0; // Adjust this value to zoom in or out

            // Request access to the user's camera
            navigator.mediaDevices.getUserMedia({ video: true })
                .then((stream) => {
                    const video = document.createElement('video');
                    video.style.objectFit = 'contain';
                    video.srcObject = stream;
                    video.play();
                    video.onloadedmetadata = () => {
                        canvas.width = video.videoWidth;
                        canvas.height = video.videoHeight;
                        detectObjects(video);
                    };
                })
                .catch((error) => {
                    console.error("Error accessing the camera:", error);
                });

            // Perform object detection
            async function detectObjects(video) {
                if (!model) return requestAnimationFrame(() => detectObjects(video));

                // Detect objects in the video stream
                const predictions = await model.detect(video);

                // Clear the canvas and draw the video frame with scaling
                ctx.clearRect(0, 0, canvas.width, canvas.height);
                ctx.drawImage(video, 0, 0, canvas.width * scaleFactor, canvas.height * scaleFactor);

                // Draw bounding boxes and labels for detected objects
                predictions.forEach(prediction => {
                    const [x, y, width, height] = prediction.bbox;
                    ctx.strokeStyle = '#00FFFF';
                    ctx.lineWidth = 4;
                    ctx.strokeRect(x * scaleFactor, y * scaleFactor, width * scaleFactor, height * scaleFactor);

                    ctx.fillStyle = '#00FFFF';
                    ctx.font = '18px Arial';
                    ctx.fillText(prediction.class, x * scaleFactor, y * scaleFactor > 10 ? y * scaleFactor - 5 : 10);
                });

                requestAnimationFrame(() => detectObjects(video));
            }
        };
    </script>
</body>
</html>